{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/veydantkatyal/fraud-snap/blob/main/fraud_snappy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eAl_am70ymP"
      },
      "source": [
        "# **PROJECT SETUP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNtxgAqsz5Tc",
        "outputId": "dab6f7b5-aa5a-460a-f137-2c1407b09d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install torch torchvision pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8an75QaM0Da8"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "import pandas as pd\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd40Ap_-0_8d"
      },
      "source": [
        "# **LOADING THE LABELLED DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ndARaxm0DYP",
        "outputId": "97797678-b039-4d87-ded7-bb7d8e4da276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "i_80mYA00DVH"
      },
      "outputs": [],
      "source": [
        "# Define the path to your dataset in Google Drive\n",
        "train_dir = '/content/drive/My Drive/doctor_bills_dataset/train'\n",
        "val_dir = '/content/drive/My Drive/doctor_bills_dataset/val'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9m62ypo1G-s"
      },
      "source": [
        "# **DATA TRANSFORMERS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ul6BFjg70DSG"
      },
      "outputs": [],
      "source": [
        "# Import necessary modules from PyTorch\n",
        "import torch\n",
        "from torch.utils.data import DataLoader  # Import DataLoader\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define transformations for train and validation sets\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Load datasets from the specified directories\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
        "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
        "\n",
        "# Define DataLoader for train and validation datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)  # DataLoader defined correctly now\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKev84jc1LI8"
      },
      "source": [
        "# **MODEL DEFINITION(RESNET50)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2-7I4uY0DPP",
        "outputId": "13ee5f9d-51ee-4610-ab84-8f05f92e4aee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 123MB/s]\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load the pre-trained ResNet50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Modify the final fully connected layer for binary classification\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # 2 output classes: genuine and forged\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3K3JL3p1SnO"
      },
      "source": [
        "# **HANDLING CLASS IMBALANCES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UknX8CA0DMj",
        "outputId": "96b59747-f216-4d91-f910-92cef53da334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of genuine documents in training set: 72\n",
            "Number of forged documents in training set: 17\n"
          ]
        }
      ],
      "source": [
        "# 2. Now handle class imbalance by calculating class weights\n",
        "import os\n",
        "\n",
        "# Check the number of images in each class for the training set\n",
        "genuine_count = len(os.listdir(os.path.join(train_dir, 'genuine')))\n",
        "forged_count = len(os.listdir(os.path.join(train_dir, 'forged')))\n",
        "total_count = genuine_count + forged_count\n",
        "\n",
        "# Print the number of genuine and forged images\n",
        "print(f\"Number of genuine documents in training set: {genuine_count}\")\n",
        "print(f\"Number of forged documents in training set: {forged_count}\")\n",
        "\n",
        "# Inverse frequency of each class to calculate weights\n",
        "genuine_weight = total_count / genuine_count\n",
        "forged_weight = total_count / forged_count\n",
        "\n",
        "# Create a tensor of weights (this will be passed to the loss function)\n",
        "class_weights = torch.tensor([genuine_weight, forged_weight], dtype=torch.float).to(device)\n",
        "\n",
        "# Use the weighted loss function\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnIQRoiT1Yra"
      },
      "source": [
        "# **LOSS FUNCTION AND OPTIMIZER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KsVu5ZZJ0DHV"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define the optimizer (SGD)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7cNCmtu1dmx"
      },
      "source": [
        "# **MODEL TRAINING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4LYY8A_0DEe",
        "outputId": "a586280b-93ac-4780-9152-2aaea2779f7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n",
            "train Loss: 0.3704 Acc: 0.7640\n",
            "val Loss: 0.2256 Acc: 0.8182\n",
            "Epoch 2/10\n",
            "----------\n",
            "train Loss: 0.2456 Acc: 0.8090\n",
            "val Loss: 0.2474 Acc: 0.8182\n",
            "Epoch 3/10\n",
            "----------\n",
            "train Loss: 0.2575 Acc: 0.8090\n",
            "val Loss: 0.3054 Acc: 0.8182\n",
            "Epoch 4/10\n",
            "----------\n",
            "train Loss: 0.2116 Acc: 0.8090\n",
            "val Loss: 0.2473 Acc: 0.8182\n",
            "Epoch 5/10\n",
            "----------\n",
            "train Loss: 0.1327 Acc: 0.8090\n",
            "val Loss: 0.1861 Acc: 0.8182\n",
            "Epoch 6/10\n",
            "----------\n",
            "train Loss: 0.1168 Acc: 0.8090\n",
            "val Loss: 0.1691 Acc: 0.8182\n",
            "Epoch 7/10\n",
            "----------\n",
            "train Loss: 0.1041 Acc: 0.8090\n",
            "val Loss: 0.1549 Acc: 0.8182\n",
            "Epoch 8/10\n",
            "----------\n",
            "train Loss: 0.0743 Acc: 0.8427\n",
            "val Loss: 0.1274 Acc: 0.8182\n",
            "Epoch 9/10\n",
            "----------\n",
            "train Loss: 0.0676 Acc: 0.8202\n",
            "val Loss: 0.1141 Acc: 0.8182\n",
            "Epoch 10/10\n",
            "----------\n",
            "train Loss: 0.0517 Acc: 0.8876\n",
            "val Loss: 0.1105 Acc: 0.8182\n"
          ]
        }
      ],
      "source": [
        "# Define the training function\n",
        "def train_model(model, criterion, optimizer, num_epochs=5):\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data\n",
        "            loader = train_loader if phase == 'train' else val_loader\n",
        "            for inputs, labels in loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Backward pass and optimization in the training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # Calculate epoch loss and accuracy\n",
        "            epoch_loss = running_loss / len(loader.dataset)\n",
        "            epoch_acc = running_corrects.double() / len(loader.dataset)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train the model for 10 epochs\n",
        "trained_model = train_model(model, criterion, optimizer, num_epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEP901bx1g5m"
      },
      "source": [
        "# **MODEL EVALUATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLvkMOEe0C60",
        "outputId": "ec985696-1036-4dea-9dc9-030c662cbf44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.8182\n",
            "Recall: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model using precision and recall\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    precision = precision_score(all_labels, all_preds, average='binary')\n",
        "    recall = recall_score(all_labels, all_preds, average='binary')\n",
        "\n",
        "    print(f'Precision: {precision:.4f}')\n",
        "    print(f'Recall: {recall:.4f}')\n",
        "\n",
        "# Evaluate the trained model\n",
        "evaluate_model(trained_model, val_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "26bCbow00TK6"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate the model and collect predictions and true labels\n",
        "def collect_predictions_and_labels(model, loader):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Turn off gradients for validation to speed up\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass to get outputs\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # Append the true labels and predictions\n",
        "            all_labels.extend(labels.cpu().numpy())  # Move labels to CPU and convert to numpy\n",
        "            all_preds.extend(preds.cpu().numpy())  # Move predictions to CPU and convert to numpy\n",
        "\n",
        "    return all_labels, all_preds\n",
        "\n",
        "# Collect predictions and true labels from validation set\n",
        "y_true, y_pred = collect_predictions_and_labels(trained_model, val_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zn_O4u720TH-"
      },
      "outputs": [],
      "source": [
        "# Assuming you are using ImageFolder for loading the dataset\n",
        "class_names = val_dataset.classes  # This will give you the class names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "0w8rWNzj0TFA",
        "outputId": "290c5056-f507-42ca-c173-2de72625ccf8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you are using ImageFolder for validation set\n",
        "class_names = val_dataset.classes  # Get class names from the validation dataset\n",
        "\n",
        "# Collect predictions and true labels from validation set\n",
        "y_true, y_pred = collect_predictions_and_labels(trained_model, val_loader)\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot confusion matrix using seaborn\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sswb_wQ0TCD",
        "outputId": "34b75d35-b334-4322-d279-87fc72e87c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as 'forgery_detection_model.pth'\n"
          ]
        }
      ],
      "source": [
        "# Save the trained model\n",
        "torch.save(trained_model.state_dict(), 'forgery_detection_model.pth')\n",
        "print(\"Model saved as 'forgery_detection_model.pth'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2NkceoM109L"
      },
      "source": [
        "# **MODEL TESTING ON VALIDATION SET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U977aEuI0S_C",
        "outputId": "5220be50-153b-4cb5-aa0b-dfb6683eb208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to 'forgery_predictions.csv'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "from torchvision import datasets\n",
        "\n",
        "# Define the function to predict on validation set and save results to CSV\n",
        "def process_and_predict_images(model, loader, class_names):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    results = []\n",
        "\n",
        "    # Loop through the validation set and make predictions\n",
        "    for inputs, labels, paths in loader:\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            confidence = torch.softmax(outputs, dim=1).max(dim=1)[0].cpu().numpy() * 100  # Confidence in percentage\n",
        "            predictions = predicted.cpu().numpy()\n",
        "\n",
        "            # Save the predictions for each file\n",
        "            for i in range(len(paths)):\n",
        "                file_name = os.path.basename(paths[i])  # Get the filename from the path\n",
        "                is_forged = bool(predictions[i])  # 0 -> genuine, 1 -> forged\n",
        "                confidence_score = confidence[i]\n",
        "                results.append((file_name, is_forged, confidence_score))\n",
        "\n",
        "    # Convert the results into a DataFrame\n",
        "    df = pd.DataFrame(results, columns=[\"file_name\", \"is_forged\", \"confidence\"])\n",
        "\n",
        "    # Save the DataFrame as a CSV file\n",
        "    df.to_csv(\"forgery_predictions.csv\", index=False)\n",
        "    print(\"Predictions saved to 'forgery_predictions.csv'\")\n",
        "\n",
        "# Custom dataset loader for getting image paths along with data\n",
        "class ImageFolderWithPaths(datasets.ImageFolder):\n",
        "    # Override the __getitem__ method to also return the image paths\n",
        "    def __getitem__(self, index):\n",
        "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
        "        path = self.imgs[index][0]\n",
        "        return original_tuple + (path,)\n",
        "\n",
        "# Load the validation dataset using the custom ImageFolder class\n",
        "val_dataset_with_paths = ImageFolderWithPaths(val_dir, transform=data_transforms['val'])\n",
        "\n",
        "# Create DataLoader for validation set with paths\n",
        "val_loader_with_paths = DataLoader(val_dataset_with_paths, batch_size=16, shuffle=False)\n",
        "\n",
        "# Call the function to predict and save results on the validation set\n",
        "process_and_predict_images(trained_model, val_loader_with_paths, val_dataset_with_paths.classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYEMLkTB16Pe"
      },
      "source": [
        "# **WEB APP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ84Rz4I0iGk",
        "outputId": "9a1811fe-073b-4a7d-e6bd-ea6873dbbcee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.0\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.8.1)\n",
            "Collecting tenacity<9,>=8.1.0 (from streamlit)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl.metadata (38 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, tenacity, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.38.0 tenacity-8.5.0 watchdog-4.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n",
        "!pip install streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB1dSNkH0iDv",
        "outputId": "13eeb3f8-3afb-4abd-fe9a-0ac50750da7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# Load the trained model (architecture + weights)\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model = models.resnet50(pretrained=False)  # Use the same model as trained\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, 2)  # Assuming binary classification (genuine vs forged)\n",
        "\n",
        "    model.load_state_dict(torch.load('forgery_detection_model.pth', map_location=torch.device('cpu')))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Define the image transformations (same as during training)\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Prediction function\n",
        "def predict_image(image, model):\n",
        "    if image.mode != \"RGB\":\n",
        "        image = image.convert(\"RGB\")\n",
        "\n",
        "    image = data_transforms(image)\n",
        "\n",
        "    if image.shape[0] != 3:\n",
        "        st.error(\"Image has an unexpected number of channels.\")\n",
        "        return None, None\n",
        "\n",
        "    image = image.unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        confidence = torch.softmax(output, dim=1).max().item() * 100\n",
        "    return predicted.item(), confidence\n",
        "\n",
        "# Streamlit app interface\n",
        "st.set_page_config(page_title=\"Document Forgery Detection\", layout=\"wide\")\n",
        "\n",
        "# Display the title and a brief description\n",
        "st.title(\"🔍 Document Forgery Detection\")\n",
        "st.markdown(\"**Upload images of documents and find out if they are _genuine_ or _forged_ using our advanced detection model.**\")\n",
        "\n",
        "# Upload images\n",
        "uploaded_files = st.file_uploader(\"Upload one or more document images:\", type=[\"jpg\", \"png\", \"jpeg\", \"tif\", \"tiff\"], accept_multiple_files=True)\n",
        "\n",
        "if uploaded_files:\n",
        "    st.write(f\"🖼️ You've uploaded {len(uploaded_files)} document(s).\")\n",
        "\n",
        "    model = load_model()  # Load model only when files are uploaded\n",
        "\n",
        "    # Create tabs for better navigation\n",
        "    tab1, tab2, tab3 = st.tabs([\"📝 Predictions\", \"📊 Download Results\", \"📖 Documentation\"])\n",
        "\n",
        "    # Tab 1: Predictions\n",
        "    with tab1:\n",
        "        st.subheader(\"📋 Results\")\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        file_names = []\n",
        "        results = []\n",
        "\n",
        "        cols = st.columns(3)  # Display images in 3-column layout\n",
        "\n",
        "        # Process and predict for each uploaded file\n",
        "        for i, uploaded_file in enumerate(uploaded_files):\n",
        "            image = Image.open(uploaded_file)\n",
        "            with cols[i % 3]:\n",
        "                st.image(image, caption=f\"{uploaded_file.name}\", use_column_width=True)\n",
        "\n",
        "                label, confidence = predict_image(image, model)\n",
        "\n",
        "                if label is not None:\n",
        "                    y_true.append(label)\n",
        "                    y_pred.append(label)\n",
        "                    file_names.append(uploaded_file.name)\n",
        "                    result_label = \"Genuine\" if label == 0 else \"Forged\"\n",
        "\n",
        "                    # Display result with color coding\n",
        "                    st.markdown(f\"<span style='color: {'green' if label == 0 else 'red'}'>**{result_label}** - Confidence: {confidence:.2f}%</span>\", unsafe_allow_html=True)\n",
        "\n",
        "                    # Store the result for later\n",
        "                    results.append({\n",
        "                        \"File Name\": uploaded_file.name,\n",
        "                        \"Result\": result_label,\n",
        "                        \"Confidence\": f\"{confidence:.2f}%\",\n",
        "                    })\n",
        "                    time.sleep(0.5)  # Simulate processing time for better UX\n",
        "\n",
        "    # Tab 2: Download Results\n",
        "    with tab2:\n",
        "        st.subheader(\"📊 Download Prediction Report\")\n",
        "        if results:\n",
        "            report_df = pd.DataFrame(results)\n",
        "            st.write(report_df)\n",
        "\n",
        "            # Allow users to download the CSV\n",
        "            csv = report_df.to_csv(index=False)\n",
        "            st.download_button(\"Download Prediction Report\", csv, \"prediction_report.csv\", \"text/csv\", key=\"download-report\")\n",
        "        else:\n",
        "            st.info(\"Please make predictions first in the 'Predictions' tab.\")\n",
        "\n",
        "    # Tab 3: Documentation\n",
        "    with tab3:\n",
        "        st.subheader(\"📖 How the Detection Works\")\n",
        "        st.markdown(\"\"\"\n",
        "        Our forgery detection model is based on ResNet50, a deep learning model pre-trained on the ImageNet dataset.\n",
        "        We fine-tuned the model using a custom dataset of genuine and forged documents.\n",
        "\n",
        "        ### Steps:\n",
        "        1. Upload one or more images in common formats (JPG, PNG, TIFF).\n",
        "        2. The model will analyze each document to determine whether it's genuine or forged.\n",
        "        3. Results include confidence scores for each prediction.\n",
        "\n",
        "        ### Limitations:\n",
        "        - The model works best with clean, high-quality images of documents.\n",
        "        - For very complex forgeries, the model may require additional tuning and training data.\n",
        "        \"\"\")\n",
        "\n",
        "else:\n",
        "    st.info(\"Please upload document images to begin the analysis.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uRVDRn3n0iA-"
      },
      "outputs": [],
      "source": [
        "# Start the Streamlit app\n",
        "!streamlit run app.py &>/dev/null&\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTAwtR5_1_Fm"
      },
      "source": [
        "# **LOCAL TUNNEL DEPLOYMENT USING NGROK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxcDLGb90h-R",
        "outputId": "caafbc3a-1404-41a9-d4e5-896431374e31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken <YOUR AUTH TOKEN>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ejHQc4nJ0urD"
      },
      "outputs": [],
      "source": [
        "!pkill ngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMkiGP4I0uoB"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Connect ngrok on port 8501 with explicit protocol\n",
        "public_url = ngrok.connect(addr='8501', proto='http')\n",
        "\n",
        "# Print the public URL where Streamlit is running\n",
        "print(f\"Streamlit app running at: {public_url}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCHpHngGTMcCYQxPd8/yHB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}